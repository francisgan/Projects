{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# League of Legends Competitive Match Data\n",
    "* **See the main project notebook for instructions to be sure you satisfy the rubric!**\n",
    "* See Project 03 for information on the dataset.\n",
    "* A few example prediction questions to pursue are listed below. However, don't limit yourself to them!\n",
    "    * Predict if a team will win or lose a game.\n",
    "    * Predict which role (top-lane, jungle, support, etc.) a player played given their post-game data.\n",
    "    * Predict how long a game will take before it happens.\n",
    "    * Predict which team will get the first Baron.\n",
    "\n",
    "Be careful to justify what information you would know at the \"time of prediction\" and train your model using only those features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of Findings\n",
    "\n",
    "\n",
    "### Introduction\n",
    "Many people loves betting online which team will win in a LOL mathcing. In this project, we will predict a team's result in a match given early game datas. It is a classification problem, since the result is either win or lose. And we will pick 'teamname', 'firstblood', 'firstdragon', 'firstherald', 'golddiffat15', 'xpdiffat15', 'csdiffat15', 'killsat15', 'assistsat15' and 'deathsat15' as features.\n",
    "\n",
    "### Baseline Model\n",
    "In baseline model we have\n",
    "    Nomimal feature:'teamname'\n",
    "    Quantitative features:'firstblood', 'firstdragon', 'firstherald', 'golddiffat15', 'xpdiffat15', 'csdiffat15', 'killsat15', 'assistsat15' and 'deathsat15'\n",
    "We leave all quantitavie features as 'is', and do Onehotcoder transform on 'teamname'\n",
    "The accuracy of our model on test set is 67.56%, which is better than just randomly pick win or lose(50% accuracy), but still not good enough.\n",
    "\n",
    "### Final Model\n",
    "In final Model, I apply more transformer.\n",
    "-I apply StdScalerByGroup() on 'golddiffat15' groupby 'league', since different league has different style of playing this game.\n",
    "-I transform boolean variable 'False' into -1, so now losing 'firstblood' and losing a resource in jungle will have negative effect.\n",
    "-I apply binarizer() on 'csdiffat15' with threshold 15; in another word, if the 'cs' difference is over the threhold now means they have lane advantage.\n",
    "\n",
    "The accuracy now increase to 74.12%.\n",
    "\n",
    "### Fairness Evaluation\n",
    "Null Hypothesis: My model is fair;the precision for 'LCK' league is same as other leagues.\n",
    "Alternative hypothesis: My model is unfair; the precision for 'LCK' league is different than other leagues.\n",
    "\n",
    "Result: The p-value is 0.225, so I can't reject my null hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'  # Higher resolution figures\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import Binarizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class StdScalerByGroup(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        :Example:\n",
    "        >>> cols = {'g': ['A', 'A', 'B', 'B'], 'c1': [1, 2, 2, 2], 'c2': [3, 1, 2, 0]}\n",
    "        >>> X = pd.DataFrame(cols)\n",
    "        >>> std = StdScalerByGroup().fit(X)\n",
    "        >>> std.grps_ is not None\n",
    "        True\n",
    "        \"\"\"\n",
    "        # X might not be a pandas DataFrame (e.g. a np.array)\n",
    "        df = pd.DataFrame(X)\n",
    "\n",
    "        # Compute and store the means/standard-deviations for each column (e.g. 'c1' and 'c2'),\n",
    "        # for each group (e.g. 'A', 'B', 'C').\n",
    "        # (Our solution uses a dictionary)\n",
    "        group = df.columns[0]\n",
    "        self.grps_ = df.groupby(group).agg(['mean', 'std']).to_dict()\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"\n",
    "        :Example:\n",
    "        >>> cols = {'g': ['A', 'A', 'B', 'B'], 'c1': [1, 2, 3, 4], 'c2': [1, 2, 3, 4]}\n",
    "        >>> X = pd.DataFrame(cols)\n",
    "        >>> std = StdScalerByGroup().fit(X)\n",
    "        >>> out = std.transform(X)\n",
    "        >>> out.shape == (4, 2)\n",
    "        True\n",
    "        >>> np.isclose(out.abs(), 0.707107, atol=0.001).all().all()\n",
    "        True\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            getattr(self, \"grps_\")\n",
    "        except AttributeError:\n",
    "            raise RuntimeError(\n",
    "                \"You must fit the transformer before tranforming the data!\")\n",
    "\n",
    "        # Hint: Define a helper function here!\n",
    "\n",
    "        df = pd.DataFrame(X)\n",
    "\n",
    "        def helper(x, col):\n",
    "            return (x[0]-self.grps_[(col, 'mean')][x[1]])/self.grps_[(col, 'std')][x[1]]\n",
    "\n",
    "        group = df.columns[0]\n",
    "        f = df.columns[1:]\n",
    "\n",
    "        for col in f:\n",
    "            df[col] = list(zip(df[col], df[group]))\n",
    "            df[col] = df[col].apply(lambda x: helper(x, col))\n",
    "\n",
    "        return df[f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gl121\\anaconda3\\envs\\dsc80\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3398: DtypeWarning: Columns (2) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>league</th>\n",
       "      <th>teamname</th>\n",
       "      <th>firstblood</th>\n",
       "      <th>firstdragon</th>\n",
       "      <th>firstherald</th>\n",
       "      <th>golddiffat15</th>\n",
       "      <th>xpdiffat15</th>\n",
       "      <th>csdiffat15</th>\n",
       "      <th>killsat15</th>\n",
       "      <th>assistsat15</th>\n",
       "      <th>deathsat15</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LCK CL</td>\n",
       "      <td>Fredit BRION Challengers</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>-1617.0</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LCK CL</td>\n",
       "      <td>Nongshim RedForce Challengers</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-107.0</td>\n",
       "      <td>1617.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LCK CL</td>\n",
       "      <td>T1 Challengers</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1763.0</td>\n",
       "      <td>-906.0</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LCK CL</td>\n",
       "      <td>Liiv SANDBOX Challengers</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1763.0</td>\n",
       "      <td>906.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LCK CL</td>\n",
       "      <td>KT Rolster Challengers</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1191.0</td>\n",
       "      <td>2298.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   league                       teamname  firstblood  firstdragon  \\\n",
       "0  LCK CL       Fredit BRION Challengers         1.0          0.0   \n",
       "1  LCK CL  Nongshim RedForce Challengers         0.0          1.0   \n",
       "2  LCK CL                 T1 Challengers         0.0          0.0   \n",
       "3  LCK CL       Liiv SANDBOX Challengers         1.0          1.0   \n",
       "4  LCK CL         KT Rolster Challengers         0.0          1.0   \n",
       "\n",
       "   firstherald  golddiffat15  xpdiffat15  csdiffat15  killsat15  assistsat15  \\\n",
       "0          1.0         107.0     -1617.0       -23.0        5.0         10.0   \n",
       "1          0.0        -107.0      1617.0        23.0        6.0         18.0   \n",
       "2          1.0       -1763.0      -906.0       -22.0        1.0          1.0   \n",
       "3          0.0        1763.0       906.0        22.0        3.0          3.0   \n",
       "4          0.0        1191.0      2298.0        15.0        3.0          8.0   \n",
       "\n",
       "   deathsat15  result  \n",
       "0         6.0       0  \n",
       "1         5.0       1  \n",
       "2         3.0       0  \n",
       "3         1.0       1  \n",
       "4         1.0       1  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "league = pd.read_csv(os.path.join('data','2022_LoL_esports_match_data_from_OraclesElixir_20221207.csv'))  #read dateset\n",
    "\n",
    "\n",
    "# data cleaning\n",
    "def clean_league(league):\n",
    "    df = league.copy()\n",
    "    df['datacompleteness'] = df['datacompleteness'].apply(\n",
    "        lambda x: True if x == 'complete' else False)\n",
    "    df[['playerid', 'teamid']].astype(\n",
    "        str).applymap(lambda x: x.split(':')[-1])  # convert id into 31 digits string\n",
    "    return df\n",
    "\n",
    "\n",
    "# takes in dataframe like league_cleaned and return two dataframe describe teams and players seperately\n",
    "def seperate_team_player(league_cleaned):\n",
    "    return league_cleaned[league_cleaned['position'] != 'team'].reset_index(drop=True), league_cleaned[league_cleaned['position']\n",
    "     == 'team'].reset_index(drop=True)\n",
    "\n",
    "team_rows = seperate_team_player(clean_league(league))[1] # focus on team data of matches\n",
    "team_rows.head()\n",
    "\n",
    "features_and_result_list = [\n",
    "    'league', 'teamname', 'firstblood', 'firstdragon', 'firstherald', 'golddiffat15', 'xpdiffat15', 'csdiffat15', 'killsat15', 'assistsat15', 'deathsat15', 'result']\n",
    "\n",
    "df = (\n",
    "    team_rows[features_and_result_list].dropna().reset_index(drop=True)\n",
    ")\n",
    "\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r^2 on train: 1.0\n",
      "accuracy on test: 0.6756247053276756\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df[['teamname', 'firstblood', 'firstdragon', 'golddiffat15', 'xpdiffat15', 'csdiffat15', 'killsat15', 'assistsat15', 'deathsat15']], \n",
    "                                                    df['result'],\n",
    "                                                    random_state=1,test_size=0.1)\n",
    "#90% train set and 10% test set\n",
    "\n",
    "\n",
    "preproc = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('keep', FunctionTransformer(lambda x:x), [\n",
    "         'firstblood', 'firstdragon', 'golddiffat15', 'xpdiffat15', 'csdiffat15', 'killsat15', 'assistsat15', 'deathsat15']),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), ['teamname'])\n",
    "    ]\n",
    ")\n",
    "\n",
    "pl = Pipeline([\n",
    "    ('preprocessor', preproc),\n",
    "    ('DecisionTreeClassifier', DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "pl.fit(x_train,y_train)\n",
    "y_pred = pl.predict(x_test)\n",
    "\n",
    "print('r^2 on train:',pl.score(x_train,y_train))\n",
    "print('accuracy on test:',(y_pred == y_test).mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7411598302687411"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df[['league','teamname', 'firstblood', 'firstdragon','golddiffat15', 'xpdiffat15', 'csdiffat15', 'killsat15', 'assistsat15', 'deathsat15']],\n",
    "                                                    df['result'],\n",
    "                                                    random_state=1, test_size=0.1)\n",
    "\n",
    "preproc = ColumnTransformer(  #now apply more transformer on features\n",
    "    transformers=[\n",
    "        ('keep', FunctionTransformer(lambda x:x), ['xpdiffat15', 'killsat15', 'assistsat15', 'deathsat15']),\n",
    "        ('zero_to_negative', FunctionTransformer(lambda x: 2*x-1), ['firstblood', 'firstdragon']),\n",
    "        ('StdScalerByGroup', StdScalerByGroup(), ['league', 'golddiffat15']),\n",
    "        ('Binarizer',Binarizer(threshold=15),['csdiffat15']),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), ['teamname'])\n",
    "    ]\n",
    ")\n",
    "\n",
    "hyperparameters = {   #values we will try in gridsearch\n",
    "    'DecisionTreeClassifier__max_depth': [2,4,6,8,10,15,20],\n",
    "    'DecisionTreeClassifier__min_samples_split': [2, 4, 6, 8, 10, 15, 20],\n",
    "}\n",
    "\n",
    "pl = Pipeline([\n",
    "    ('preprocessor', preproc),\n",
    "    ('DecisionTreeClassifier', DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "searcher = GridSearchCV(pl, hyperparameters, cv=5)\n",
    "\n",
    "searcher.fit(x_train, y_train)\n",
    "y_pred = searcher.predict(x_test)\n",
    "\n",
    "(y_pred == y_test).mean()  #accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fairness Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>league</th>\n",
       "      <th>actual</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LCO</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SL</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VCS</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LCK CL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   league  actual  predict\n",
       "0     LCO       1        1\n",
       "1      SL       1        1\n",
       "2      CT       0        0\n",
       "3     VCS       0        1\n",
       "4  LCK CL       0        0"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fairness_df = x_test[['league']].copy()\n",
    "fairness_df['actual'] = y_test\n",
    "fairness_df['predict'] = y_pred\n",
    "fairness_df = fairness_df.reset_index(drop=True)\n",
    "fairness_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.224"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lck = fairness_df[fairness_df['league']=='LCK']\n",
    "non_lck = fairness_df[fairness_df['league'] !='lck']\n",
    "lck_precision = metrics.precision_score(lck['actual'], lck['predict'])\n",
    "non_lck_precision = metrics.precision_score(non_lck['actual'], non_lck['predict'])\n",
    "obs_diff = abs(lck_precision-non_lck_precision)\n",
    "\n",
    "n=1000\n",
    "result=[]\n",
    "for _ in range(n):\n",
    "    df = fairness_df.copy()\n",
    "    df['league'] = df['league'].sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    lck = fairness_df[df['league']=='LCK']\n",
    "    non_lck = fairness_df[df['league'] !='lck']\n",
    "\n",
    "    lck_precision = metrics.precision_score(lck['actual'], lck['predict'])\n",
    "    non_lck_precision = metrics.precision_score(non_lck['actual'], non_lck['predict'])\n",
    "\n",
    "    result.append(abs(lck_precision-non_lck_precision))\n",
    "\n",
    "(result>=obs_diff).mean() #p-value\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('dsc80')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e356033cf64b1c3ff450f59ac375038070f3f05a18350721a11008c6295fdfde"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
