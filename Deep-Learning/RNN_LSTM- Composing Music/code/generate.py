from util import *
from constants import *
from SongRNN import *
import torch
import torch.optim as optim
import torch.nn as nn
import numpy as np

def softmax_with_temperature(logits, temperature):
    exp_logits = np.exp(logits / temperature)
    return exp_logits / np.sum(exp_logits)

def sample_char(probabilities):
    probabilities = np.squeeze(probabilities)
    return np.random.choice(len(probabilities), p=probabilities)

def generate_song(model, device, char_idx_map, max_len=1000, temp=0.8, prime_str='<start>', show_heatmap=False):
    """
    Generates a song using the provided model.

    Parameters:
    - model (nn.Module): The trained model used for generating the song
    - device (torch.device): The device (e.g., "cpu" or "cuda") on which the model is located
    - char_idx_map (dict): A map of characters to their index
    - max_len (int): The maximum length of the generated song
    - temp (float): Temperature parameter for temperature scaling during sampling
    - prime_str (str): Initialize the beginning of the song

    Returns:
    - generated_song (str): The generated song as a string
    """

    #Move model to the specified device and set the model to evaluation mode
    model.to(device)
    model.eval()

    # Initialize the hidden state
    model.init_hidden()
        

    with torch.no_grad(): # we don't need to calculate the gradient in the validation/testing
        # "build up" hidden state using the beginging of a song '<start>'
        generated_song = prime_str
        
        # prime input
        prime = characters_to_tensor(generated_song, char_idx_map).to(device)
        for i in range(len(prime)-1):
             _ = model(prime[i].unsqueeze(0)) 

        '''
        TODOs: 
            - Continue generating the rest of the sequence until reaching the maximum length or encountering the end token.
            - Incorporate the temperature parameter to determine the generated/predicted character.
            - Add the generated character to the `generated_song` and then return `generated_song`.
        '''
        
        end_token = '<end>'
        search_for_end = False
        end_token_encountered = False
        token_idx = 1
        input_seq = prime[i].unsqueeze(0) # a character
        i = 0
        
        while ((i < max_len) and not end_token_encountered): # condition changing in the while loop
            output, _ = model(input_seq) #input is a character 
            probabilities = nn.functional.softmax(output / temp, dim=-1)
            char_index = sample_char(probabilities.cpu().numpy())
            
            # if we encounter the beginning of <end>, start checking for the rest of the sequence
            if char_index == char_idx_map.get(end_token[0]):
                search_for_end = True         
            elif search_for_end:
                if (char_index == char_idx_map.get(end_token[token_idx])):
                    # we found the next character, continue searching
                    token_idx += 1
                else:
                    # the sequence is not continuous, reset search
                    search_for_end = False
            
            # if search for end correctly encountered end token, end 
            if token_idx == len(end_token):
                end_token_encountered = True

            next_char = get_character_from_index(char_idx_map, char_index)  # You need to implement this function
            generated_song += next_char

            generated_output = characters_to_tensor(next_char, char_idx_map).to(device)
            input_seq = generated_output # if sequence, need to torch.cats
            i += 1 

        # Turn the model back to training mode
        model.train()

        if show_heatmap:
            # TODO: Call the generate_heatmap function to form the heatmap
            tensor_song = characters_to_tensor(generated_song, char_idx_map).to(device)
            output, activations = model(tensor_song)
            generate_heatmap(generated_song, activations)
            
        return generated_song

def generate_heatmap(generated_song, heatmap, neuron_idx=2):
    """
    Generates a heatmap using the provided generated song, heatmap chart values and neuron id.

    Parameters:
    - generated_song (nn.Module): The song generated by a trained model.
    - heatmap (torch.Tensor): heatmap/activation values from a particular layer of the trained model.
    - neuron_idx (int): id of the neuron to plot heatmap for.

    Returns:
        None
    """
    pad_factor = 20
    heatmap = heatmap.cpu().detach().numpy()
    data = np.append(heatmap[:,neuron_idx], 0.0)
    padded_song, padded_data = pad(generated_song, data, pad_factor=pad_factor)

    padded_song = np.reshape(padded_song, (len(padded_song)//pad_factor, pad_factor))
    padded_data = np.reshape(padded_data, (len(padded_data)//pad_factor, pad_factor))

    plt.figure(figsize=(heatmap.shape[0]//4,heatmap.shape[1]//4))
    plt.title(f"Heatmap For Song RNN, Neuron ID: {neuron_idx}")
    heatplot = plt.pcolor(padded_data, edgecolors='k', linewidths=4, cmap='RdBu_r', vmin=-1.0, vmax=1.0)

    show_values(heatplot, song=padded_song)
    plt.colorbar(heatplot)
    plt.gca().invert_yaxis()
    plt.savefig(f"./plots/heatmap_{neuron_idx}.png")
    print(f"==> Heatmap saved for Neuron ID: {neuron_idx}..")
    return
