{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "feff4fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-15 06:07:17.034721: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from torch.utils.data import Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.decomposition import PCA\n",
    "# import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# tqdm.pandas()\n",
    "\n",
    "from transformers import pipeline, AutoTokenizer,GPT2Tokenizer, GPT2Model, AutoTokenizer, AutoModelForCausalLM\n",
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertTokenizer, BertForMaskedLM, AdamW\n",
    "from tqdm import tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "505c3823",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.empty_cache()\n",
    "# print(torch.cuda.memory_summary())\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70d5f3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/8000_data.csv\")\n",
    "df = df.dropna()\n",
    "df['original_text'] = df['original_text'].apply(lambda x: x[:200])\n",
    "df['rewritten_text'] = df['rewritten_text'].apply(lambda x: x[:200])\n",
    "\n",
    "df = df[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a5a39c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "If you want to use `BertLMHeadModel` as a standalone, add `is_decoder=True.`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertLMHeadModel(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (transform_act_fn): GELUActivation()\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=30522, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = AutoModelForCausalLM.from_pretrained('bert-base-uncased')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12577cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "631950f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MaskedSequenceDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, mask_token='[MASK]'):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.dataframe = dataframe\n",
    "        self.mask_token = mask_token\n",
    "\n",
    "        self.dataframe['original_text'] = dataframe['original_text'].apply(lambda x: re.sub('<.*?>', '', x).strip())\n",
    "        self.dataframe['rewritten_text'] = dataframe['rewritten_text'].apply(lambda x: re.sub('<.*?>', '', x).strip())\n",
    "        self.dataframe['rewrite_prompt'] = dataframe['prompt'].apply(lambda x: re.sub('<.*?>', '', x).strip())\n",
    "\n",
    "    def combine_and_mask(self, original, rewrite, prompt_length):\n",
    "        masks = \" \".join([self.mask_token for _ in range(prompt_length)])\n",
    "        masked_sequence = f\"{original} The task is to rewrite this narrative with the given blanks: {masks} {rewrite}\"\n",
    "        return masked_sequence\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataframe.iloc[idx]\n",
    "        prompt = row['rewrite_prompt']\n",
    "        \n",
    "        target_subsequence_ids = self.tokenizer.encode(prompt, add_special_tokens=False)\n",
    "\n",
    "        masked_sequence = self.combine_and_mask(row['original_text'], row['rewritten_text'], len(target_subsequence_ids))\n",
    "        \n",
    "        inputs = self.tokenizer(masked_sequence, truncation=True, padding='max_length', max_length=512, return_tensors=\"pt\")\n",
    "        input_ids = inputs['input_ids'].squeeze(0)\n",
    "        \n",
    "        labels = torch.full_like(input_ids, fill_value=-100)\n",
    "        \n",
    "        mask_indices = (input_ids == self.tokenizer.mask_token_id).nonzero(as_tuple=False).squeeze()\n",
    "        if len(mask_indices) >= len(target_subsequence_ids):\n",
    "            labels[mask_indices[:len(target_subsequence_ids)]] = torch.tensor(target_subsequence_ids, dtype=torch.long)\n",
    "        else:\n",
    "            raise ValueError(\"Not enough mask tokens to fit the rewrite prompt\")\n",
    "\n",
    "        return input_ids, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e4aa810",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "train_df, test_df = train_test_split(df, test_size=0.2)\n",
    "\n",
    "train_dataset = MaskedSequenceDataset(train_df, tokenizer)\n",
    "test_dataset = MaskedSequenceDataset(test_df, tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d417a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce59bf8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65c5af53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'bert.pooler.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/home/z4xia/.local/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Epoch 1/15:   0%|          | 0/50 [00:00<?, ?batch/s]We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
      "Epoch 1/15: 100%|██████████| 50/50 [00:29<00:00,  1.68batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at epoch 1: 4.4658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/15: 100%|██████████| 50/50 [00:29<00:00,  1.72batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at epoch 2: 2.8903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/15: 100%|██████████| 50/50 [00:28<00:00,  1.76batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at epoch 3: 2.3139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/15: 100%|██████████| 50/50 [00:29<00:00,  1.68batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at epoch 4: 1.8673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/15: 100%|██████████| 50/50 [00:29<00:00,  1.71batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at epoch 5: 1.5831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/15: 100%|██████████| 50/50 [00:28<00:00,  1.73batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at epoch 6: 1.3350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/15: 100%|██████████| 50/50 [00:28<00:00,  1.76batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at epoch 7: 1.1343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/15: 100%|██████████| 50/50 [00:29<00:00,  1.70batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at epoch 8: 0.8650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/15: 100%|██████████| 50/50 [00:28<00:00,  1.74batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at epoch 9: 0.7224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/15: 100%|██████████| 50/50 [00:29<00:00,  1.70batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at epoch 10: 0.5600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/15: 100%|██████████| 50/50 [00:29<00:00,  1.68batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at epoch 11: 0.4381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/15: 100%|██████████| 50/50 [00:29<00:00,  1.68batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at epoch 12: 0.4278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/15: 100%|██████████| 50/50 [00:29<00:00,  1.67batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at epoch 13: 0.4514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/15: 100%|██████████| 50/50 [00:29<00:00,  1.67batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at epoch 14: 0.2829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/15: 100%|██████████| 50/50 [00:29<00:00,  1.69batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at epoch 15: 0.2292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "model.train()\n",
    "model.to(device) \n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "epochs = 15\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{epochs}\", unit=\"batch\"):\n",
    "        input_ids, labels = batch\n",
    "        input_ids = input_ids.to(device)  # or 'cpu'\n",
    "        labels = labels.to(device)  # or 'cpu'\n",
    "        \n",
    "        model.zero_grad()\n",
    "        \n",
    "        outputs = model(input_ids, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Average loss at epoch {epoch + 1}: {avg_loss:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fcf43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model after training\n",
    "# model.save_pretrained('model/fill_blanks.pth')\n",
    "# tokenizer.save_pretrained('model/fill_blanks_tokenizer.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cab25662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_cosine_similarity(x1, x2):\n",
    "    x1_norm = torch.nn.functional.normalize(x1, p=2, dim=-1)\n",
    "    x2_norm = torch.nn.functional.normalize(x2, p=2, dim=-1)\n",
    "    \n",
    "    cos_sim = torch.mm(x1_norm, x2_norm.transpose(0, 1))\n",
    "    \n",
    "    return cos_sim\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "scs_model = SentenceTransformer(\"sentence-t5-base\")\n",
    "\n",
    "def sharpened_cosine_similarity_batch(scs_model, output_texts, target_texts, sharpen_factor=3):\n",
    "    target_embeddings = scs_model.encode(target_texts, convert_to_tensor=True)\n",
    "    output_embeddings = scs_model.encode(output_texts, convert_to_tensor=True)\n",
    "    \n",
    "    cos_sims = batch_cosine_similarity(target_embeddings, output_embeddings)\n",
    "    \n",
    "    sharpened_scores = [cos_sims[i][i].unsqueeze(0) ** sharpen_factor for i in range(cos_sims.size(0))]\n",
    "    \n",
    "    return sharpened_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aff494a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: re the essence text in text into a a ai scientist narrative . narrative . my wheels adventure through the celestial romance , ign narrative . my wheels adventure through the celestial romance , igniting the rest re the essence text in text into a a ai scientist narrative . my wheels adventure through the celestial romance , essence text in text into a a ai scientist narrative . my wheels adventure through the rest the rest re the essence text in text into a a ai scientist narrative . my wheels adventure in text into a a ai scientist narrative . my wheels adventure narrative . my wheels adventure through the celestial romance , igniting the olfactory senses the essence text in text into a a ai scientist narrative . my wheels adventure text in text into a a ai scientist narrative . my wheels adventure through the celestial romance rest the rest re the essence text in text into a a ai scientist narrative . my wheels adventure through the in text into a a ai scientist narrative . my wheels adventure through the celestial ai scientist narrative . my wheels adventure through the celestial romance , igniting the olfactory senses a ai scientist narrative . my wheels adventure through the celestial romance , igniting the through the celestial romance , igniting the olfactory senses with the pungent aroma re the essence text in text into a a ai scientist narrative . my wheels\n",
      "Labels: rewrite this text in the style of a detective alien planet . planet . [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] planet . [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] rewrite this text in the style of a detective alien planet . [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] this text in the style of a detective alien planet . [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] rewrite this text in the style of a detective alien planet . [UNK] [UNK] [UNK] in the style of a detective alien planet . [UNK] [UNK] [UNK] planet . [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]write this text in the style of a detective alien planet . [UNK] [UNK] [UNK] text in the style of a detective alien planet . [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] rewrite this text in the style of a detective alien planet . [UNK] [UNK] [UNK] [UNK] [UNK] in the style of a detective alien planet . [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] detective alien planet . [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] a detective alien planet . [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] rewrite this text in the style of a detective alien planet . [UNK] [UNK]\n",
      "Predicted: convey the same message as this text but through eyes eyes a scientist scientist philosophical novel . message as this text but through eyes eyes a scientist scientist philosophical novel . the tapestry of human relationships a myriad threads , explorer an intricate tapestry of experiences . each encounter , of a . the tapestry of human relationships , woven a myriad threads , explorer an the same message as this text but through eyes eyes a blank text text convey the same message as this text but through eyes eyes a scientist scientist philosophical novel . message as this text but through eyes eyes a scientist scientist philosophical novel . the text convey the same message as this text but through eyes eyes a this text but through eyes eyes a scientist scientist philosophical novel . the tapestry of but through eyes eyes a scientist scientist philosophical novel . the tapestry of human relationships , woven same message as this text but through eyes eyes a scientist scientist philosophical novel . text but through eyes eyes a scientist scientist philosophical novel . the tapestry of human relationships , woven a myriad threads , text blank text text convey the same message as this text text blank text text convey the same message as this text but through eyes eyes a scientist scientist of a leaf knight dancing in the wind , carries a unique the same message as this text but through eyes eyes a scientist scientist philosophical novel\n",
      "Labels: convey the same message as this text but through the eyes of a philosophical inquiry explorer . message as this text but through the eyes of a philosophical inquiry explorer . [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] . [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] the same message as this text but through the eyes of [UNK] [UNK] [UNK] convey the same message as this text but through the eyes of a philosophical inquiry explorer . message as this text but through the eyes of a philosophical inquiry explorer . [UNK] [UNK] convey the same message as this text but through the eyes of this text but through the eyes of a philosophical inquiry explorer . [UNK] [UNK] [UNK] but through the eyes of a philosophical inquiry explorer . [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] same message as this text but through the eyes of a philosophical inquiry explorer . text but through the eyes of a philosophical inquiry explorer . [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] convey the same message as this text [UNK] [UNK] [UNK] [UNK] convey the same message as this text but through the eyes of a philosophical [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] the same message as this text but through the eyes of a philosophical inquiry explorer\n",
      "Predicted: imagine this text was a knight knight in world of knight , how would it be written ? text to rewrite this narrative time the text blank text text search a droid . the task text to rewrite this narrative time the text blank to search a droid . the task text to rewrite this narrative time the text blank text text imagine this the task text to rewrite this narrative time the text blank text text imagine . would detective of to search a droid . the task text to rewrite this droid . the task text to rewrite this narrative time the text blank text text imagine thisoid . the task text to rewrite this narrative time the text blank text text imagine thisoid . the task text to rewrite this narrative time the text blank text text imagine this text . would detective of to search a droid . the task text to rewrite this narrative time the rewrite this narrative time the text blank text text imagine explorer . would detective of to search a droid . the droid . the task text to rewrite this narrative time the text blank text text text to rewrite this narrative time the text blank text text imagine this text . the task text to rewrite this narrative time the text blank text text imagine this text was a knight imagine this text was a knight knight in world of knight , how would it be written ?\n",
      "Labels: imagine this text was a tragedy in the world of knight , how would it be written ? [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] imagine this [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] imagine [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] imagine this [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] imagine this [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] imagine this text [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] imagine [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] imagine this text [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] imagine this text was a tragedy imagine this text was a tragedy in the world of knight , how would it be written ?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: translate the essence of this text into a story narrative . this narrative rest the text rest text translate translate the essencewrite this narrative rest the text rest text translate translate the essence of this text into story narrative . narrative action adventureled with the adventure of smoke action story translate the essence of this text into a story narrative . narrative action adventureled with . narrative action adventureled with the adventure of smoke action story as narrative rest the text rest text translate translate the essence of this text into a story narrative . narrative text into a story narrative . narrative action adventureled with the adventure of smoke action into a story narrative . narrative action adventureled with the adventure of smoke action story as rewrite this narrative rest the text rest text translate translate the essence of this text into a story narrative essence of this text into a story narrative . narrative action adventureled with the the essence of this text into a story narrative . narrative action adventureled with the the essence of this text into a story narrative . narrative action adventureled with the adventure of translate the essence of this text into a story narrative . narrative action adventureled with the essence of this text into a story narrative . narrative action adventure text into a story narrative . narrative action adventureled with the adventure of\n",
      "Labels: translate the essence of this text into a detective narrative . [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] translate the essence [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] translate the essence of this text into detective narrative . [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] translate the essence of this text into a detective narrative . [UNK] [UNK] [UNK] [UNK] [UNK] . [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] translate the essence of this text into a detective narrative . [UNK] text into a detective narrative . [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] into a detective narrative . [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] translate the essence of this text into a detective narrative essence of this text into a detective narrative . [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] the essence of this text into a detective narrative . [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] the essence of this text into a detective narrative . [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] translate the essence of this text into a detective narrative . [UNK] [UNK] [UNK] [UNK] [UNK] the essence of this text into a detective narrative . [UNK] [UNK] [UNK] text into a detective narrative . [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
      "Predicted: translate the essence of this text into a noir detective narrative . narrative conclusion the essence the translate the translate the essence of translate the essence of this text into a noir detective narrative . the scent noir detective narrative . the scent a a and a perfume . heavy in the air time essence the translate the translate the essence of this text into a noir detective narrative . the scent a a and a perfume . essence the translate the translate the essence of this text into the translate the essence of this text into a noir detective narrative . the scent a a of to rewrite the narrative conclusion the essence the translate the translate the translate the translate the essence of this text into a noir detective narrative . the scent a a text into a noir detective narrative . the scent a a and a perfume . heavy in the air the essence the translate the translate the essence of this text into a noirwrite the narrative conclusion the essence the translate the translate the essence of this text narrative conclusion the essence the translate the translate the essence of the translate the essence of this text into a noir detective narrative translate the essence of this text into a noir detective narrative . the scent a a and a perfume the essence the translate the translate the essence of this text into a noir detective narrative . the scent\n",
      "Labels: translate the essence of this text into a noir detective narrative . [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] translate the essence of translate the essence of this text into a noir detective narrative . [UNK] [UNK] noir detective narrative . [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] translate the essence of this text into a noir detective narrative . [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] translate the essence of this text into [UNK] translate the essence of this text into a noir detective narrative . [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] translate [UNK] [UNK] [UNK] translate the essence of this text into a noir detective narrative . [UNK] [UNK] [UNK] [UNK] text into a noir detective narrative . [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] translate the essence of this text into a noir [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] translate the essence of this text [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] translate the essence of [UNK] translate the essence of this text into a noir detective narrative translate the essence of this text into a noir detective narrative . [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] translate the essence of this text into a noir detective narrative . [UNK] [UNK]\n",
      "Predicted: reyle this text in if style of a a alien planet time wizard . alien planet time wizard . a symphony echoes through the cosmos , from the dance of celestial bodies . rest capital : reyle this text in if style of a a reyle this text in if style of a a alien planet time wizard . time wizard . a symphony echoes through the cosmos , from the dance of celestial reyle this text in if style of a a alien planet time wizard . alien planet time wizard . a symphony echoes through the cosmos , a alien planet time wizard . a symphony echoes through the cosmos , from the dance of celestial reyle this text in if style of a a alien planet time wizard . a of a a alien planet time wizard . a symphony echoes through rest capital : reyle this text in if style of a a alien planet this text in if style of a a alien planet time wizard . a symphony echoes through the cosmos , rest capital : reyle this text in if style of a a alien planet time wizard . a this text in if style of a a alien planet time wizard . a symphony echoes in if style of a a alien planet time wizard . a symphony echoes style of a a alien planet time wizard . a symphony echoes through the cosmos , from the dance of celestial bodies\n",
      "Labels: restyle this text as if it were written by a scientist from knight . a scientist from knight . [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] restyle this text as if it were written by restyle this text as if it were written by a scientist from knight . from knight . [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] restyle this text as if it were written by a scientist from knight . a scientist from knight . [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] by a scientist from knight . [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] restyle this text as if it were written by a scientist from knight . [UNK] were written by a scientist from knight . [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] restyle this text as if it were written by a scientist this text as if it were written by a scientist from knight . [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] restyle this text as if it were written by a scientist from knight . [UNK] this text as if it were written by a scientist from knight . [UNK] [UNK] [UNK] as if it were written by a scientist from knight . [UNK] [UNK] [UNK] it were written by a scientist from knight . [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: convey the same message as this text but through the eyes a a a cats detective . text : convey the same message as this text but through the eyes a a a rewrite this narrative rest the text text text : convey the this narrative rest the text text text : convey the same message as this text but through the text : convey the same message as this text but through the eyes a a a cats detective : convey the same message as this text but through the eyes is to rewrite this narrative rest the text text text : convey the same message rest the text text text : convey the same message as this same message as this text but through the eyes a a a cats detective . the same message as this text but through the eyes a a a cats detective . . listen text text : convey the same message as this text but through the eyes a a a cats detective . to rewrite this narrative rest the text text text : convey the same message as this text but the text text text : convey the same message as this text but through the eyes rewrite this narrative rest the text text text : convey the same message as thiswrite this narrative rest the text text text : convey the same message as this text but through the eyes a a text but through the eyes a a a cats detective . . listen\n",
      "Labels: convey the same message as this text but through the eyes of a scientist noir detective . [UNK] [UNK] convey the same message as this text but through the eyes of a scientist [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] convey the [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] convey the same message as this text but through the [UNK] [UNK] convey the same message as this text but through the eyes of a scientist noir detective [UNK] convey the same message as this text but through the eyes [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] convey the same message [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] convey the same message as this same message as this text but through the eyes of a scientist noir detective . the same message as this text but through the eyes of a scientist noir detective . [UNK] [UNK] [UNK] [UNK] [UNK] convey the same message as this text but through the eyes of a scientist noir detective . [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] convey the same message as this text but [UNK] [UNK] [UNK] [UNK] [UNK] convey the same message as this text but through the eyes [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] convey the same message as this [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] convey the same message as this text but through the eyes of a text but through the eyes of a scientist noir detective . [UNK] [UNK]\n",
      "Predicted: adapt the text as a script for a through dystyst dystop future setting . text as a script for a through dystyst dystop future setting the rest text text : adapt the text as a script for a through dystyst dystyst dystop future setting . setting text setting about adapt the text as a script for a through dystyst dystop future setting . a through dystyst dystop future setting . setting text setting about the future a s rest text text : adapt the text as a script for a through text as a script for a through dystyst dystop future setting . through dystyst dystop future setting . setting text setting about the setting . setting text setting about the future a s futureystyst dystop future setting . setting text setting about the future dystyst dystop future setting . setting text setting about the future a through dystyst dystop future setting . setting text setting as a script for a through dystyst dystop future setting . setting as a script for a through dystyst dyst text : adapt the text as a script for a through dystyst dystop future setting .\n",
      "Labels: adapt this text as a script for a dystopian future in a comedy setting . text as a script for a dystopian future in a comedy setting [UNK] [UNK] [UNK] [UNK] [UNK] adapt this text as a script for a dystopian futureopian future in a comedy setting . [UNK] [UNK] [UNK] [UNK] adapt this text as a script for a dystopian future in a comedy setting . a dystopian future in a comedy setting . [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] adapt this text as a script for a d text as a script for a dystopian future in a comedy setting . dystopian future in a comedy setting . [UNK] [UNK] [UNK] [UNK] [UNK] setting . [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]opian future in a comedy setting . [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]ystopian future in a comedy setting . [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] a dystopian future in a comedy setting . [UNK] [UNK] [UNK] as a script for a dystopian future in a comedy setting . [UNK] as a script for a dystopian future in [UNK] [UNK] adapt this text as a script for a dystopian future in a comedy setting .\n",
      "Predicted: convey the same message as this text but through the eyes a time time traveler . text blank rest rest convey the same message as this text but through eyes a time time traveler . . i ' ve journeyed through the through the eyes a time time traveler . . i ' ve journeyed through the labyrinth of time same message as this text but through the eyes a time time traveler . . i ' ve journey from the text blank rest rest convey the same message as this text but through the eyes the same message as this text but through the eyes a time time traveler . . convey the same message as this text but through the eyes a time time traveler message as this text but through the eyes a time time traveler . . time time traveler . . i ' ve journeyed through the labyrinth of time , explorer in this text but through the eyes a time time traveler . . i ' ve journey the same message as this text but through the eyes a text blank rest rest convey the same message as this text but through the eyes a time message as this text but through the eyes a time time traveler . . i ' ve journeyed as this text but through the eyes a time time traveler . . text but through the eyes a time time traveler . . i ' ve journeyed\n",
      "Labels: restyle this text as if it were written by a explorer from horror story . [UNK] [UNK] [UNK] [UNK] restyle this text as if it were written a explorer from horror story . [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] written by a explorer from horror story . [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] this text as if it were written by a explorer from horror story . [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] restyle this text as if it were written by ayle this text as if it were written by a explorer from horror story . [UNK] restyle this text as if it were written by a explorer from horror story text as if it were written by a explorer from horror story . [UNK] from horror story . [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] if it were written by a explorer from horror story . [UNK] [UNK] [UNK] [UNK] [UNK]yle this text as if it were written by a explorer [UNK] [UNK] [UNK] [UNK] restyle this text as if it were written by a explorer from text as if it were written by a explorer from horror story . [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] as if it were written by a explorer from horror story . [UNK] it were written by a explorer from horror story . [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
      "Predicted: rewrite this text in the style of a alien ancient inquiry .xir that ignites within me a romance of eu with the text rest re : rewrite this text in the style of a alien ancient inquiry . . rest re : rewrite this text in the style of a alien ancient with the text rest re : rewrite this text in the style of a alien of a alien ancient inquiry . . alien alien alien alien the text rest re : rewrite this text in the style of a alien ancient inquiry . this text in the style of a alien ancient inquiry . . alien alien alien alien brethren , i alien alien brethren , i planet planet a celestial thexir that ign this text in the style of a alien ancient inquiry . . alien alien : rewrite this text in the style of a alien ancient inquiry this text in the style of a alien ancient inquiry . . alien alien with the text rest re : rewrite this text in the style of a alien ancient the narrative with the text rest re : rewrite this text in the style of a alien ancient inquiry . . alienwrite the narrative with the text rest re : rewrite this text in the style of a\n",
      "Labels: rewrite this text in the style of a alien planet scientist . [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] rewrite this text in the style of a alien planet scientist . [UNK] [UNK] [UNK] [UNK] rewrite this text in the style of a alien planet [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] rewrite this text in the style of a alien of a alien planet scientist . [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] rewrite this text in the style of a alien planet scientist . this text in the style of a alien planet scientist . [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] this text in the style of a alien planet scientist . [UNK] [UNK] [UNK] [UNK] rewrite this text in the style of a alien planet scientist this text in the style of a alien planet scientist . [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] rewrite this text in the style of a alien planet [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] rewrite this text in the style of a alien planet scientist . [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] rewrite this text in the style of a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: imagine this text was a this in in the world of superhero , how would it fi written ? from the text blank rest : imagine this text was a this in in the blank rest : imagine this text was a this in in the world of superhero , narrative from the text blank rest : imagine this text was a this in was a this in in the world of superhero , how would it fi written to rewrite this narrative from the text blank rest : imagine this text text was a this in in the world of superhero , how would it fi rewrite this narrative from the text blank rest : imagine this : imagine this text was a this in in the world of superhero , how would it in the world of superhero , how would it fi written ? was a this in in the world of superhero , how would it fi written ?write this narrative from the text blank rest : imagine this text was a this in in the world of a this in in the world of superhero , how would it fi written ? ? my dear gentleman this narrative from the text blank rest : imagine this text was a this in rest : imagine this text was a this in in the world of superhero , how a this in in the world of superhero , how would it fi written ? ?\n",
      "Labels: imagine this text was a superhero in the world of victorian gentleman , how would it be written ? [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] imagine this text was a superhero in the world [UNK] [UNK] [UNK] imagine this text was a superhero in the world of victorian gentleman , [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] imagine this text was a superhero in was a superhero in the world of victorian gentleman , how would it be written [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] imagine this text text was a superhero in the world of victorian gentleman , how would it be [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] imagine this [UNK] imagine this text was a superhero in the world of victorian gentleman , how would it the world of victorian gentleman , how would it be written ? was a superhero in the world of victorian gentleman , how would it be written ? [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] imagine this text was a superhero in the world of victorian a superhero in the world of victorian gentleman , how would it be written ? [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] imagine this text was a superhero in [UNK] [UNK] imagine this text was a superhero in the world of victorian gentleman , how a superhero in the world of victorian gentleman , how would it be written ? [UNK]\n",
      "Predicted: imagine this text was a victorian in in in world of inquiry , would would it be written ? in in in world of inquiry , would would it be written text was a victorian in in in world of inquiry , would would it this text was a victorian in in in world of inquiry , would would in in in world of inquiry , would would it be written ? ? text was a victorian in in in world of inquiry , would in in in world of inquiry , would would it be written ? would would it be written ? ? a detective in the world text text imagine this text was a victorian in in in world of a victorian in in in world of inquiry , would would it be written ? ? would it be written ? ? a detective in the world of philosophical inquiry , the would it be written ? ? a detective in the world of philosophical inquiry , time with the text blank text text imagine this text was a victorian in in in world of philosophical inquiry , the text would be written in a was a victorian in in in world of inquiry , would would , would would it be written ? ? a detective in the world of philosophical inquiry , the\n",
      "Labels: imagine this text was a detective in the world of philosophical inquiry , how would it be written ? in the world of philosophical inquiry , how would it be written text was a detective in the world of philosophical inquiry , how would it this text was a detective in the world of philosophical inquiry , how would in the world of philosophical inquiry , how would it be written ? [UNK] text was a detective in the world of philosophical inquiry , how in the world of philosophical inquiry , how would it be written ? how would it be written ? [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] imagine this text was a detective in the world of philosophical a detective in the world of philosophical inquiry , how would it be written ? [UNK] would it be written ? [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] would it be written ? [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] imagine this text was a detective in the world of [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] was a detective in the world of philosophical inquiry , how would , how would it be written ? [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n",
      "Predicted: rewrite this text in the style style a a action from tragedy . the given rest rest : rewrite this text in thewrite this narrative with the given rest rest : rewrite this text in the style style a villain . the essence of to rewrite this narrative with the given rest rest : rewrite this rewrite this narrative with the given rest rest : rewrite this text in the style the essence of to rewrite this narrative with the given rest rest with the given rest rest : rewrite this text in the style style a a action from tragedy . lovecraftwrite this text in the style style a a action from tragedy . love\n",
      "Labels: rewrite this text in the style of a victorian gentleman action adventure . [UNK] [UNK] [UNK] [UNK] [UNK] rewrite this text in the [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] rewrite this text in the style of a [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] rewrite this [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] rewrite this text in the style [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] rewrite this text in the style of a victorian gentleman action adventure . [UNK] [UNK]write this text in the style of a victorian gentleman action adventure . [UNK]\n"
     ]
    }
   ],
   "source": [
    "predicts = []\n",
    "targets = []\n",
    "for batch in test_loader:\n",
    "    input_ids, labels = batch\n",
    "    input_ids = input_ids.to('cuda')\n",
    "    # Make predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids)\n",
    "        predictions = outputs.logits.argmax(dim=-1)\n",
    "        \n",
    "        labels_index = (labels != -100).nonzero(as_tuple=True)[1]\n",
    "        \n",
    "        labels_idx = labels[0,labels_index]\n",
    "        label_tokens = tokenizer.convert_ids_to_tokens(labels_idx)\n",
    "        label_sentences = tokenizer.convert_tokens_to_string(label_tokens)\n",
    "\n",
    "        predicted_idx = predictions[0,labels_index]\n",
    "        predicted_tokens = tokenizer.convert_ids_to_tokens(predicted_idx)\n",
    "        predicted_sentences = tokenizer.convert_tokens_to_string(predicted_tokens)\n",
    "\n",
    "        print(\"Predicted:\", predicted_sentences)\n",
    "        print(\"Labels:\", label_sentences)\n",
    "        predicts.append(predicted_sentences)\n",
    "        targets.append(label_sentences)\n",
    "    \n",
    "\n",
    "\n",
    "score = sharpened_cosine_similarity_batch(scs_model, predicts, targets, sharpen_factor=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47572f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8198d1be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7949, device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = torch.mean(torch.stack(score))\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db9e8ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
